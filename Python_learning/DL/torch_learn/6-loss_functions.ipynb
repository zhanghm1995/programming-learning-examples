{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Resources\n",
    "[all-pytorch-loss-function](https://analyticsindiamag.com/all-pytorch-loss-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntroypLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8719, -1.0069,  0.4193,  0.0851,  0.3153],\n",
      "        [-1.4044,  1.0306, -0.3020, -0.3410,  0.4111],\n",
      "        [ 0.2907, -0.6874, -0.5904, -1.2338, -1.3248]], requires_grad=True) torch.Size([3, 5])\n",
      "tensor([1, 3, 4]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input, input.shape)\n",
    "print(target, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.0002)\n",
      "=========method2=========\n",
      "tensor(0.9000)\n",
      "tensor([11.0004, 19.0000])\n",
      "tensor([2.2001, 1.9000])\n",
      "tensor(13.6669) mean\n",
      "tensor(4.1001)\n",
      "=========method2=========\n",
      "tensor(1.9000)\n",
      "tensor(1.9000)\n"
     ]
    }
   ],
   "source": [
    "from mmdet.models.losses import CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred_score = torch.tensor([[13., 3., 2., 5.],\n",
    "                           [1., 8., 20., 2.]])\n",
    "target = torch.tensor([2, 0])\n",
    "\n",
    "class_weight = [0.1, 0.2, 0.2, 0.4]\n",
    "class_weight = torch.tensor(class_weight)\n",
    "\n",
    "def method1():\n",
    "    \"\"\"https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
    "    \"\"\"\n",
    "    loss = F.cross_entropy(pred_score, target, ignore_index=255)\n",
    "    print(loss)\n",
    "\n",
    "\n",
    "def method2():\n",
    "    print(\"=========method2=========\")\n",
    "    print(torch.sum(class_weight))\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    loss_ce = loss(pred_score, target)\n",
    "    print(loss_ce)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(weight=class_weight, reduction='none')\n",
    "    loss_ce = loss(pred_score, target)\n",
    "    print(loss_ce)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(weight=class_weight, reduction='mean')\n",
    "    loss_ce = loss(pred_score, target)\n",
    "    print(loss_ce, 'mean')\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(weight=class_weight, reduction='sum')\n",
    "    loss_ce = loss(pred_score, target)\n",
    "    print(loss_ce)\n",
    "    print(\"=========method2=========\")\n",
    "\n",
    "def method3():\n",
    "    pred_score = torch.tensor([[13., 3., 2., 5.],\n",
    "                           [1., 8., 20., 2.]])\n",
    "    target = torch.tensor([2, 0])\n",
    "\n",
    "    class_weight = [0.1, 0.2, 0.2, 0.4]\n",
    "    class_weight = torch.tensor(class_weight)\n",
    "    \n",
    "    loss = CrossEntropyLoss(use_sigmoid=False, \n",
    "                            class_weight=class_weight, \n",
    "                            reduction='mean', \n",
    "                            loss_weight=1.0)\n",
    "    mask = torch.tensor([0, 1])\n",
    "    loss_ce = loss(pred_score, target, mask, avg_factor=1)\n",
    "    print(loss_ce)\n",
    "\n",
    "    mask = torch.tensor([False, True])\n",
    "    pred_score = pred_score[mask]\n",
    "    target = target[mask]\n",
    "    loss_ce = loss(pred_score, target)\n",
    "    print(loss_ce)\n",
    "\n",
    "\n",
    "# pred_score = torch.tensor([[13., 3., 2., 5., 1.],\n",
    "#                            [1., 8., 20., 2., 3.],\n",
    "#                            [1., 14., 3., 5., 3.]])\n",
    "# print(pred_score)\n",
    "# pred_score_soft = F.softmax(pred_score, dim=1)\n",
    "# print(pred_score_soft)\n",
    "# pred_score_soft_log = pred_score_soft.log()\n",
    "\n",
    "# target = torch.tensor([3, 1, 255])\n",
    "# loss = F.cross_entropy(pred_score, target, ignore_index=255)\n",
    "# print(loss)\n",
    "\n",
    "method1()\n",
    "method2()\n",
    "method3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8465, -1.6065],\n",
      "        [ 1.8283,  0.2340],\n",
      "        [-1.2583,  0.0607]], requires_grad=True) torch.Size([3, 2])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [1]]) torch.Size([3, 1])\n",
      "tensor(1.3752, grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        # Implementation from\n",
    "        # Translating Images to Maps, Saha et al., ICRA\n",
    "        # https://github.com/avishkarsaha/translating-images-into-maps/blob/main/src/model/loss.py#L261-L272\n",
    "        label = label.float()\n",
    "        intersection = 2 * pred * label\n",
    "        union = pred + label\n",
    "        iou = (intersection.float().sum(dim=0).sum(dim=-1).sum(dim=-1)) / (\n",
    "            union.float().sum(dim=0).sum(dim=-1).sum(dim=-1) + 1e-5\n",
    "        )\n",
    "        loss_mean = 1 - iou.mean()\n",
    "\n",
    "        return loss_mean\n",
    "    \n",
    "\n",
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "target = torch.empty((3, 1), dtype=torch.long).random_(2)\n",
    "print(input, input.shape)\n",
    "print(target, target.shape)\n",
    "\n",
    "loss = DiceLoss()\n",
    "loss_ce = loss(input, target)\n",
    "print(loss_ce)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred = torch.randn(4, 200, 200, 16, 18)\n",
    "target = torch.randn(4, 200, 200, 16, 18)\n",
    "\n",
    "pred = torch.randn(4, 18)\n",
    "target = torch.randn(4, 18)\n",
    "T = 10\n",
    "\n",
    "\n",
    "kd_loss = F.kl_div(\n",
    "        F.log_softmax(pred / T, dim=1), target, reduction='none').mean(1) * (\n",
    "            T * T)\n",
    "print(kd_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 18]) torch.Size([4])\n",
      "tensor(0.2225)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmdet.models.losses import KnowledgeDistillationKLDivLoss, FocalLoss\n",
    "from mmdet.models.losses import CrossEntropyLoss\n",
    "\n",
    "def test_kl_loss():\n",
    "    kl_loss = KnowledgeDistillationKLDivLoss()\n",
    "\n",
    "    pred = torch.randn(4, 18)\n",
    "    target = torch.randn(4, 18)\n",
    "    weight = torch.randn(4)\n",
    "    print(weight.shape)\n",
    "    dd = pred.reshape(2, -1)\n",
    "    print(dd.shape)\n",
    "\n",
    "    loss = kl_loss(pred, target, weight)\n",
    "    print(loss)\n",
    "\n",
    "def test_focal_loss():\n",
    "    focal_loss = FocalLoss()\n",
    "\n",
    "    pred = torch.randn(4, 18)\n",
    "    target = torch.randint(0, 15, (4,))\n",
    "    print(pred.shape, target.shape)\n",
    "\n",
    "    loss = focal_loss(pred, target)\n",
    "    print(loss)\n",
    "\n",
    "test_focal_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5]) torch.Size([2])\n",
      "tensor(1.)\n",
      "tensor(1.5061)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmdet.models.losses import FocalLoss\n",
    "\n",
    "pred = torch.tensor([[0.1, 0.2, 0.3, -0.5, 0.6],\n",
    "                     [0.2, 0.3, 0.4, -0.5, 0.6]])\n",
    "target = torch.tensor([0, 4])\n",
    "print(pred.shape, target.shape)\n",
    "num_classes = pred.size(1)\n",
    "focal_loss = FocalLoss()\n",
    "\n",
    "num_pos_occ = torch.sum(target < 4)\n",
    "occ_avg_factor = num_pos_occ * 1.0\n",
    "print(occ_avg_factor)\n",
    "loss = focal_loss(pred, target, avg_factor=occ_avg_factor)\n",
    "\n",
    "# target = F.one_hot(target, num_classes=num_classes + 1)\n",
    "# target = target[:, :num_classes]\n",
    "# print(target)\n",
    "# loss = F.binary_cross_entropy_with_logits(\n",
    "#     pred, target, reduction='none')\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.],\n",
      "         [ 4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.],\n",
      "         [ 8.,  9.],\n",
      "         [10., 11.]]])\n",
      "tensor([[[12., 11.],\n",
      "         [10.,  9.],\n",
      "         [ 8.,  7.]],\n",
      "\n",
      "        [[ 6.,  5.],\n",
      "         [ 4.,  3.],\n",
      "         [ 2.,  1.]]]) torch.Size([2, 3, 2])\n",
      "tensor([[[12., 10.],\n",
      "         [ 8.,  6.],\n",
      "         [ 4.,  2.]],\n",
      "\n",
      "        [[ 0.,  2.],\n",
      "         [ 4.,  6.],\n",
      "         [ 8., 10.]]]) torch.Size([2, 3, 2]) loss\n",
      "tensor(6.) loss mean\n",
      "tensor(6.) loss\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data1 = torch.arange(12).reshape(2, 3, 2).to(torch.float32)\n",
    "data2 = torch.arange(12, 0, -1).reshape(2, 3, 2).to(torch.float32)\n",
    "print(data1)\n",
    "print(data2, data2.shape)\n",
    "\n",
    "loss_none = F.l1_loss(data1, data2, reduction='none')\n",
    "print(loss_none, loss_none.shape, \"loss\")\n",
    "\n",
    "loss = F.l1_loss(data1, data2, reduction='mean')\n",
    "print(loss, \"loss mean\")\n",
    "\n",
    "loss = loss_none.sum() / data1.numel()\n",
    "print(loss, \"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.],\n",
      "         [ 4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.],\n",
      "         [ 8.,  9.],\n",
      "         [10., 11.]]])\n",
      "tensor([[[12., 11.],\n",
      "         [10.,  9.],\n",
      "         [ 8.,  7.]],\n",
      "\n",
      "        [[ 6.,  5.],\n",
      "         [ 4.,  3.],\n",
      "         [ 2.,  1.]]]) torch.Size([2, 3, 2])\n",
      "tensor(7.) tensor(5.)\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data1 = torch.arange(12).reshape(2, 3, 2).to(torch.float32)\n",
    "data2 = torch.arange(12, 0, -1).reshape(2, 3, 2).to(torch.float32)\n",
    "print(data1)\n",
    "print(data2, data2.shape)\n",
    "\n",
    "data11 = data1[0]\n",
    "data21 = data2[0]\n",
    "\n",
    "data12 = data1[1]\n",
    "data22 = data2[1]\n",
    "\n",
    "loss1 = F.l1_loss(data11, data21, reduction='mean')\n",
    "loss2 = F.l1_loss(data12, data22, reduction='mean')\n",
    "print(loss1, loss2)\n",
    "\n",
    "loss = torch.stack([loss1, loss2]).mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc_loss_with_different_methods\n",
      "tensor([[[16., 14.],\n",
      "         [12., 10.],\n",
      "         [ 8.,  6.],\n",
      "         [ 4.,  2.]],\n",
      "\n",
      "        [[ 0.,  2.],\n",
      "         [ 4.,  6.],\n",
      "         [ 8., 10.],\n",
      "         [12., 14.]]]) torch.Size([2, 4, 2])\n",
      "tensor(8.)\n",
      "tensor(8.)\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "### https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html\n",
    "def cal_loss(input, target):\n",
    "    \"\"\"\n",
    "    MAE计算细节\n",
    "    \"\"\"\n",
    "    print(target - input)\n",
    "    print(torch.abs(target - input))\n",
    "    ### Calculate the absolute\n",
    "    diff = input - target\n",
    "    abs_diff = torch.abs(diff)\n",
    "    mae = torch.mean(abs_diff)\n",
    "    print(mae)\n",
    "\n",
    "\n",
    "def calc_loss_with_different_methods(pred, tgt):\n",
    "    print(\"calc_loss_with_different_methods\")\n",
    "    ## Method 1\n",
    "    l1_loss = nn.L1Loss(reduction='none')\n",
    "    output = l1_loss(pred, tgt)\n",
    "    print(output, output.shape)\n",
    "    \n",
    "    output = torch.mean(output) # the same with nn.L1Loss(reduction='mean')\n",
    "    print(output)\n",
    "\n",
    "    ## Method 2\n",
    "    l1_loss = nn.L1Loss()\n",
    "    output = l1_loss(pred, tgt)\n",
    "    print(output)\n",
    "\n",
    "    ## Method 3\n",
    "    output = F.l1_loss(pred, tgt)\n",
    "    print(output)\n",
    "\n",
    "\n",
    "pred = torch.arange(16).reshape(2, 4, 2).to(torch.float32)\n",
    "target = torch.arange(16, 0, step=-1).reshape(2, 4, 2).to(torch.float32)\n",
    "\n",
    "calc_loss_with_different_methods(pred, target)\n",
    "\n",
    "\n",
    "# mae_loss = nn.L1Loss(reduction='mean')\n",
    "# input = torch.randn(3, 5)\n",
    "# target = torch.randn(3, 5)\n",
    "# target = torch.tensor([[1,2,3,4,5],[1,2,3,4,5], [1,2,3,4,5.0]])\n",
    "# target = torch.tensor([[1,2,3,4,5.0]])\n",
    "\n",
    "# print(input, target)\n",
    "# cal_loss(input, target)\n",
    "\n",
    "# output = mae_loss(input, target)\n",
    "# print(output, output.shape)\n",
    "\n",
    "# target = torch.tensor([[1,2,3,4,5],[1,2,3,4,5], [1,2,3,4,5.0]])\n",
    "# output = mae_loss(input, target)\n",
    "# print(output, output.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2222)\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8., 11.]])\n",
      "tensor([[1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(1.2222)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def pixel_wise_loss(pred, target, mask=None, weight=1.0):\n",
    "    l1_dist = F.l1_loss(pred, target, reduction=\"none\")\n",
    "\n",
    "    if mask is None:\n",
    "        return torch.mean(l1_dist)\n",
    "    \n",
    "    loss1 = weight * l1_dist * mask\n",
    "    loss2 = l1_dist * (1 - mask)\n",
    "    \n",
    "    loss = torch.mean(loss1 + loss2)\n",
    "    return loss\n",
    "\n",
    "pred = torch.arange(0, 9).reshape(3, 3).to(torch.float32)\n",
    "\n",
    "# target = torch.arange(9, 0, -1).reshape(3, 3).to(torch.float32)\n",
    "target = torch.arange(1, 10).reshape(3, 3).to(torch.float32)\n",
    "# target[0, 0] += 2\n",
    "\n",
    "target[2, 2] += 2\n",
    "\n",
    "\n",
    "print(pred)\n",
    "print(target)\n",
    "\n",
    "mask = torch.zeros_like(target)\n",
    "mask[:2, :2] = 1.\n",
    "print(mask)\n",
    "\n",
    "loss = pixel_wise_loss(pred, target)\n",
    "# loss = pixel_wise_loss(pred, target, mask=mask, weight=2.0)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mse_criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "pred = torch.tensor([[0, 2, 2, 4]], dtype=torch.float32)\n",
    "target = torch.tensor([[2, 3, 4, 5]], dtype=torch.float32)\n",
    "\n",
    "mse_loss = mse_criterion(pred, target)\n",
    "print(mse_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Pytorch实现\n",
    "input = torch.randn(3, 4, requires_grad=True)\n",
    "target = torch.randn(3, 4)\n",
    "mse_loss = nn.MSELoss()\n",
    "output = mse_loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print('input -: ', input)\n",
    "print('target -: ', target)\n",
    "print('output -: ', output)\n",
    "\n",
    "pred = torch.arange(0, 9).reshape(3, 3).to(torch.float32) / 9.0\n",
    "# pred[0, 0] = 0.5\n",
    "# pred[2, 2] = 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target = torch.arange(9, 0, -1).reshape(3, 3).to(torch.float32) / 9.0\n",
    "print(target)\n",
    "\n",
    "pred[2] = target[2]\n",
    "# pred[2, :2] = target[2, :2]\n",
    "print(pred)\n",
    "\n",
    "class WeightedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        weight = -torch.log(1 - target + 1e-5)\n",
    "        weighted_diff = torch.multiply((pred - target), weight)\n",
    "        \n",
    "        return torch.sum(torch.pow(weighted_diff, 2))\n",
    "\n",
    "mse_loss = WeightedLoss()\n",
    "output = mse_loss(pred, target)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy(nn.BCELoss)\n",
    "[https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\n",
    "\n",
    "[https://gombru.github.io/2018/05/23/cross_entropy_loss/](https://gombru.github.io/2018/05/23/cross_entropy_loss/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE error is: 0.43800269247783435\n"
     ]
    }
   ],
   "source": [
    "### Python实现\n",
    "y_pred = np.array([0.1580, 0.4137, 0.2285])\n",
    "y_true = np.array([0.0, 1.0, 0.0]) #2 labels: (0,1)\n",
    "def BCE(y_pred, y_true):\n",
    "    total_bce_loss = np.sum(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
    "    # Getting the mean BCE loss\n",
    "    num_of_samples = y_pred.shape[0]\n",
    "    mean_bce_loss = total_bce_loss / num_of_samples\n",
    "    return mean_bce_loss\n",
    "bce_value = BCE(y_pred, y_true)\n",
    "print (\"BCE error is: \" + str(bce_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n",
      "tensor(0.4380, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Using Pytorch implementation\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "sigmoid = torch.nn.Sigmoid() # Ensuring inputs are between 0 and 1\n",
    "input = torch.tensor(y_pred)\n",
    "target = torch.tensor(y_true)\n",
    "print(input.shape, target.shape)\n",
    "output = bce_loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCEWithLogitsLoss(nn.BCEWithLogitsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410],\n",
      "        [-0.2934],\n",
      "        [-2.1788]]) tensor([[1.],\n",
      "        [0.],\n",
      "        [2.]]) torch.float32\n",
      "tensor(1.7387)\n",
      "tensor(1.7387)\n"
     ]
    }
   ],
   "source": [
    "from mmdet.models.losses import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "bce_loss = CrossEntropyLoss(use_sigmoid=True)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "input = torch.randn((3, 1))\n",
    "target = torch.empty((3, 1)).random_(3)\n",
    "print(input, target, target.dtype)\n",
    "\n",
    "loss = bce_loss(input, target)\n",
    "print(loss)\n",
    "\n",
    "loss = F.binary_cross_entropy_with_logits(input, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "tensor([[-1.2800],\n",
      "        [ 0.0282],\n",
      "        [ 0.9930]], requires_grad=True)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor(0.4132, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss(weight=torch.tensor([1.0, 1.0, 1.0]))\n",
    "input = torch.randn(3, 1, requires_grad=True)\n",
    "print(input.shape)\n",
    "\n",
    "target = torch.empty((3, 1)).random_(2)\n",
    "output = loss(input, target)\n",
    "print(input.shape, target.shape)\n",
    "print(input)\n",
    "print(target)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.1664],\n",
      "        [81.5843],\n",
      "        [26.2562],\n",
      "        [48.3878],\n",
      "        [67.6504],\n",
      "        [75.3911],\n",
      "        [26.2691],\n",
      "        [ 4.2840],\n",
      "        [20.8029],\n",
      "        [11.8037],\n",
      "        [12.1695],\n",
      "        [73.5599],\n",
      "        [71.1765],\n",
      "        [78.7581],\n",
      "        [41.8305],\n",
      "        [90.1415]])\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9864],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "torch.Size([16, 1])\n",
      "tensor(0.6931)\n",
      "tensor(27.6075)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def example1():\n",
    "    model = nn.Linear(10, 1)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    x = torch.randn(16, 10)\n",
    "    y = torch.empty(16).random_(2)  # (16, )\n",
    "    print(y, y.shape)\n",
    "\n",
    "    out = model(x)  # (16, 1)\n",
    "    out = out.squeeze(dim=-1)  # (16, )\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    loss = criterion(y, y)\n",
    "    print(loss)\n",
    "\n",
    "def example2():\n",
    "    torch.manual_seed(100)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion2 = nn.BCELoss()\n",
    "\n",
    "    pred = torch.rand(16,1) * 100\n",
    "    print(pred)\n",
    "\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    print(sigmoid(pred))\n",
    "\n",
    "    target = torch.zeros_like(pred)\n",
    "    print(target.shape)\n",
    "\n",
    "    loss = criterion(target, pred)\n",
    "    print(loss)\n",
    "\n",
    "    print(criterion2(target, sigmoid(pred)))\n",
    "\n",
    "example2()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineEmbeddingLoss\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "tensor(-1.1176e-08)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "v1 = torch.randn((16, 64))\n",
    "v2 = torch.randn((16, 64))\n",
    "v2 = v1 * 0.6\n",
    "\n",
    "target = torch.ones((v1.shape[0]))\n",
    "print(target.shape)\n",
    "\n",
    "loss = criterion(v1, v2, target)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/haimingzhang/miniconda3/envs/GAN/lib/python3.6/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/haimingzhang/miniconda3/envs/GAN/lib/python3.6/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "torch.Size([])\n",
      "tensor(0.4945, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import lpips\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg') # closer to \"traditional\" perceptual loss, when used for optimization\n",
    "\n",
    "import torch\n",
    "img0 = torch.zeros(1,3,64,64) # image should be RGB, IMPORTANT: normalized to [-1,1]\n",
    "img1 = torch.ones(1,3,64,64)\n",
    "d = torch.mean(loss_fn_vgg(img0, img1))\n",
    "print(d.shape)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input1 = torch.randn(50, 128, 1)\n",
    "input2 = torch.randn(1, 128, 100)\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)\n",
    "print(output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Variation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "\n",
    "def total_variation_loss(img):\n",
    "    bs_img, c_img, h_img, w_img = img.size()\n",
    "    tv_h = torch.pow(img[:,:,1:,:]-img[:,:,:-1,:], 2).sum()\n",
    "    tv_w = torch.pow(img[:,:,:,1:]-img[:,:,:,:-1], 2).sum()\n",
    "    return (tv_h + tv_w) / (bs_img*c_img*h_img*w_img)\n",
    "\n",
    "img = cv2.imread(\"/home/zhanghm/Research/V100/programming-learning-examples/Python_learning/data/obama.jpg\")\n",
    "img_pred = torch.rand(1,3,64,64)\n",
    "img_pred = torch.FloatTensor(img)[None] / 255\n",
    "img_pred = img_pred.permute(0,3,1,2)\n",
    "\n",
    "loss = total_variation_loss(img_pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bevdet_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "addcddd066d5ef72f980905a6458e788367133afdc8cba3eb26f6e87a17fe289"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
