{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from icecream import ic as print"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create torch tensors\n",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x.shape: torch.Size([3]), x.dtype: torch.int64\n",
      "ic| type(tensor_shape): <class 'torch.Size'>\n",
      "    len(tensor_shape): 1\n",
      "    x.ndim: 1\n",
      "ic| data.dtype: torch.float32, data.shape: torch.Size([3])\n",
      "ic| data.dtype: torch.bool\n",
      "ic| x.shape: torch.Size([3]), x.dtype: torch.float32\n",
      "ic| data.dtype: torch.float32\n",
      "ic| data.dtype: torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Basic creator\n",
    "## torch.tensor创建tensor的dtype与原始类型保持一致\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(x.shape, x.dtype)\n",
    "\n",
    "tensor_shape = x.shape\n",
    "print(type(tensor_shape), len(tensor_shape), x.ndim)\n",
    "\n",
    "data = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(data.dtype, data.shape)\n",
    "\n",
    "data = torch.tensor([True, False, True])\n",
    "print(data.dtype)\n",
    "\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float32) # we can specify the dtype\n",
    "print(x.shape, x.dtype)\n",
    "\n",
    "## use torch.Tensor,官方不推荐使用,建议使用torch.tensor\n",
    "# https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor.__init__\n",
    "data = torch.Tensor([1, 2, 3])  ## torch.Tensor is torch.TensorFloat32 by default\n",
    "print(data.dtype)\n",
    "\n",
    "data = torch.Tensor([True, False, True])\n",
    "print(data.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x.shape: torch.Size([4]), x.dtype: torch.float32\n",
      "ic| x.shape: torch.Size([3, 5])\n",
      "    x.dtype: torch.float32\n",
      "    x.min(): tensor(0.0076)\n",
      "    x.max(): tensor(0.9782)\n",
      "ic| x.shape: torch.Size([2, 3])\n",
      "    x.dtype: torch.float32\n",
      "    x.min(): tensor(0.0310)\n",
      "    x.max(): tensor(0.9137)\n",
      "ic| x.shape: torch.Size([3, 5])\n",
      "    x.min(): tensor(-1.3378)\n",
      "    x.max(): tensor(2.5334)\n",
      "ic| y.min(): tensor(0.0095)\n",
      "    y.max(): tensor(0.9544)\n",
      "    y.dtype: torch.float32\n",
      "    y.shape: torch.Size([3, 5])\n",
      "ic| int_tensor.shape: torch.Size([10])\n",
      "    int_tensor.dtype: torch.int64\n",
      "    int_tensor.min(): tensor(0)\n",
      "    int_tensor.max(): tensor(4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.int64, tensor(0), tensor(4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from icecream import ic as print\n",
    "\n",
    "\n",
    "### Random creator\n",
    "x = torch.rand(4)\n",
    "print(x.shape, x.dtype)\n",
    "\n",
    "x = torch.rand((3, 5)) # 生成0-1的随机数\n",
    "print(x.shape, x.dtype, x.min(), x.max()) # is torch.float32 by default\n",
    "\n",
    "x = torch.rand(2, 3) # 指定的size可以直接写数字,也可以写tuple或list\n",
    "print(x.shape, x.dtype, x.min(), x.max())\n",
    "\n",
    "x = torch.randn(3, 5) # 生成标准正态分布的随机数\n",
    "print(x.shape, x.min(), x.max())\n",
    "\n",
    "# use rand_like to generate uniform distribution numbers with same shape\n",
    "y = torch.rand_like(x) # [0, 1.0]\n",
    "print(y.min(), y.max(), y.dtype, y.shape)\n",
    "\n",
    "int_tensor = torch.randint(5, (10, )) # int64 dtype\n",
    "print(int_tensor.shape, int_tensor.dtype, int_tensor.min(), int_tensor.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| data.dtype: torch.float32, data.shape: torch.Size([2, 3])\n",
      "ic| data_ones.dtype: torch.float32\n",
      "    data_ones.shape: torch.Size([2, 3])\n",
      "ic| y.shape: torch.Size([2, 3])\n",
      "    y.dtype: torch.float32\n",
      "    input.dtype: torch.float32\n",
      "ic| y.shape: torch.Size([2, 3])\n",
      "    y.dtype: torch.int64\n",
      "    input.dtype: torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.int64, torch.int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.zeros(2, 3) # zeros is float32 by default\n",
    "print(data.dtype, data.shape)\n",
    "\n",
    "data_ones = torch.ones(2, 3, dtype=torch.float32)\n",
    "print(data_ones.dtype, data_ones.shape)\n",
    "\n",
    "## use zeros_like or ones_like\n",
    "input = torch.rand((2, 3))\n",
    "y = torch.zeros_like(input)\n",
    "print(y.shape, y.dtype, input.dtype)\n",
    "\n",
    "input = torch.randint(10, (2, 3))\n",
    "y = torch.zeros_like(input) # with the same dtype with input\n",
    "print(y.shape, y.dtype, input.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 11, 10]) torch.float32 tensor(0.) tensor(255.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "image = torch.randint(0, 256, (3, 11, 10)).float()\n",
    "print(image.shape, image.dtype, image.min(), image.max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanghm/miniconda3/envs/py38-torch100-cu11/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.]) torch.Size([4]) 2.5\n",
      "tensor([[ 0.0031,  0.0000, -1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0039, -1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = [1, 2, 3, 4]\n",
    "tensor = torch.Tensor(input)\n",
    "print(tensor, tensor.shape, tensor.mean().item())\n",
    "\n",
    "normalize_matrix = torch.tensor([[1/((640-1)/2), 0, -1, 0], [0, 1/((512-1)/2), -1, 0], [0,0,1,0], [0,0,0,1]])\n",
    "print(normalize_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create special tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 1]) torch.float32 (10, 5)\n",
      "<class 'torch.Size'>\n",
      "torch.Size([10, 5, 257])\n",
      "torch.Size([5, 1]) torch.int32\n",
      "torch.Size([1]) tensor(0, dtype=torch.int32)\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]) torch.float32\n",
      "tensor([1., 1., 1., 1., 1.]) torch.float32 torch.Size([5])\n",
      "torch.Size([1, 1024, 256])\n",
      "tensor([[ 1.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanghm/miniconda3/envs/py38-torch100-cu11/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "## Create special tensors\n",
    "### All zeros or all ones creator\n",
    "y = torch.zeros((10, 5, 1)) # float32 by default\n",
    "print(y.shape, y.dtype, tuple(y.shape[:2]))\n",
    "\n",
    "y = torch.zeros((5, 1)).int() # convert to int32\n",
    "print(y.shape, y.dtype)\n",
    "\n",
    "y = torch.zeros(1).int()\n",
    "print(y.shape, y[0])\n",
    "\n",
    "## Identity matrix\n",
    "I = torch.eye(4)\n",
    "print(I, I.dtype)\n",
    "\n",
    "\n",
    "all_ones_tensor = torch.ones(5)\n",
    "print(all_ones_tensor, all_ones_tensor.dtype, all_ones_tensor.shape)\n",
    "\n",
    "## Create the empty tensor\n",
    "shape = (1, 1024, 256)\n",
    "t = torch.empty(*shape)\n",
    "print(t.shape)\n",
    "\n",
    "## Create diagonal matrix\n",
    "coord_trans = torch.diag(torch.tensor([1, -1, -1, 1], dtype=torch.float32))\n",
    "print(coord_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| arr.shape: torch.Size([10]), arr.dtype: torch.int64\n",
      "ic| data1: tensor([[[ 0,  1],\n",
      "                    [ 2,  3],\n",
      "                    [ 4,  5]],\n",
      "           \n",
      "                   [[ 6,  7],\n",
      "                    [ 8,  9],\n",
      "                    [10, 11]]])\n",
      "    data1.shape: torch.Size([2, 3, 2])\n",
      "ic| data2: tensor([[[1, 2]],\n",
      "           \n",
      "                   [[3, 4]]])\n",
      "    data2.shape: torch.Size([2, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2]],\n",
       " \n",
       "         [[3, 4]]]),\n",
       " torch.Size([2, 1, 2]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "## Create arange tensor\n",
    "arr = torch.arange(0, 10)\n",
    "print(arr.shape, arr.dtype)\n",
    "\n",
    "data1 = torch.arange(12).reshape(2, 3, 2)\n",
    "print(data1, data1.shape)\n",
    "\n",
    "data2 = torch.arange(1, 5).reshape(2, 1, 2)\n",
    "print(data2, data2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensor from numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (3, 4, 5) float32\n",
      "torch.Size([3, 4, 5]) torch.float32\n",
      "torch.Size([3, 4, 5]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "## ============ Create tensor from numpy matrix ===============\n",
    "import numpy as np\n",
    "\n",
    "np_array = np.random.random((3, 4, 5)).astype(np.float32) # np.float64 by default\n",
    "print(type(np_array), np_array.shape, np_array.dtype)\n",
    "\n",
    "# by using torch.from_numpy function\n",
    "tensor_array = torch.from_numpy(np_array)\n",
    "print(tensor_array.shape, tensor_array.dtype)\n",
    "\n",
    "# using torch.tensor function also ok\n",
    "tensor_array = torch.tensor(np_array)\n",
    "print(tensor_array.shape, tensor_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| data.dtype: dtype('float64')\n",
      "ic| data_new.shape: torch.Size([2, 3, 4])\n",
      "    data_new.dtype: torch.float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((2, 3, 4))\n",
    "print(data.dtype)\n",
    "\n",
    "data_new = torch.from_numpy(data)\n",
    "print(data_new.shape, data_new.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1]) torch.float32\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "torch.Size([1, 10, 1]) torch.float32\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([4, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((10, 1))\n",
    "print(y.shape, y.dtype)\n",
    "\n",
    "print(y)\n",
    "y = torch.unsqueeze(y, 0)\n",
    "print(y.shape, y.dtype)\n",
    "print(y)\n",
    "\n",
    "\n",
    "input_data = torch.rand((4, 60, 8))\n",
    "input_data = input_data[:, :8]\n",
    "print(input_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9]) torch.int64\n",
      "tensor([[10, 11, 12, 13, 14, 15, 16, 17, 18]]) torch.Size([1, 9])\n",
      "tensor([[8, 7, 6]]) tensor([[8],\n",
      "        [7],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "label = torch.arange(10, 19)\n",
    "print(label.shape, label.dtype)\n",
    "\n",
    "label = label.view(1,-1)\n",
    "print(label, label.shape)\n",
    "\n",
    "_, pred = label.topk(3, 1, True, True)\n",
    "print(pred, pred.t())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create torch tensors - Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create right shifted matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5041,  0.6514, -0.3396,  0.4546,  0.3332],\n",
      "         [-0.0036, -0.6595,  0.0423,  0.8735, -0.6663],\n",
      "         [ 1.3240, -1.1321, -0.7364,  0.2649,  1.3023],\n",
      "         [-0.9993,  0.5696,  0.2285, -1.1304, -0.4896]],\n",
      "\n",
      "        [[ 3.0797, -0.4287,  0.6457,  0.5229, -0.1737],\n",
      "         [-1.1057, -1.9149,  0.3974,  1.0938,  0.8098],\n",
      "         [ 2.6179,  1.9122,  0.5650, -1.2638,  0.7957],\n",
      "         [-0.5098,  0.0470,  1.4643, -0.7093,  2.1780]]])\n",
      "torch.Size([2, 4, 5])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.5041,  0.6514, -0.3396,  0.4546,  0.3332],\n",
      "         [-0.0036, -0.6595,  0.0423,  0.8735, -0.6663],\n",
      "         [ 1.3240, -1.1321, -0.7364,  0.2649,  1.3023],\n",
      "         [-0.9993,  0.5696,  0.2285, -1.1304, -0.4896]]])\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "def _generate_shifted_target(target: Tensor):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        target (Tensor): (Sy, B, C)\n",
    "\n",
    "    Returns:\n",
    "        _type_: shifted target with a inserted start token\n",
    "    \"\"\"\n",
    "    ret = torch.zeros_like(target)\n",
    "    ret[1:, ...] = target[:-1, ...]\n",
    "    return ret\n",
    "\n",
    "target = torch.randn((2, 4, 5))\n",
    "print(target)\n",
    "shifted_target = _generate_shifted_target(target)\n",
    "print(shifted_target.shape)\n",
    "print(shifted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xs.shape: torch.Size([10]), ys.shape: torch.Size([10])\n",
      "ic| xs.shape: torch.Size([10, 1])\n",
      "ic| ys.shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = torch.randn(10, 2)\n",
    "xs, ys = locations[:, 0], locations[:, 1]\n",
    "print(xs.shape, ys.shape)\n",
    "xs = xs[:, None]\n",
    "print(xs.shape)\n",
    "\n",
    "ys = ys[None]\n",
    "print(ys.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masked matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf],\n",
      "        [0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_subsequent_mask(seq_len):\n",
    "    \"\"\"Generate future masked matrix\n",
    "\n",
    "    Args:\n",
    "        seq_len int): sequence length\n",
    "\n",
    "    Returns:\n",
    "        Tensor: (seq_len, seq_len) dimension\n",
    "    \"\"\"\n",
    "    mask = (torch.triu(torch.ones(seq_len, seq_len)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "masked_matrix = generate_subsequent_mask(4)\n",
    "print(masked_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False,  True,  True]])\n",
      "torch.Size([3, 5, 4]) torch.Size([3, 5, 1])\n",
      "tensor([[[0.2455, 0.5985, 0.7856, 0.8820],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4024, 0.1510, 0.2556, 0.8236],\n",
      "         [0.1437, 0.3919, 0.0533, 0.4486],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3731, 0.3793, 0.7705, 0.9820],\n",
      "         [0.4504, 0.8001, 0.7164, 0.3064],\n",
      "         [0.0375, 0.4668, 0.8711, 0.9600],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((3, 5, 4))\n",
    "\n",
    "lengths = torch.tensor([1, 2, 3])\n",
    "batch_size, max_len, _ = x.shape\n",
    "# create mask for padded elements and zero-out them\n",
    "mask = torch.arange(max_len, device=lengths.device).expand(batch_size, max_len) >= lengths[:, None]\n",
    "print(mask)\n",
    "mask = ~mask[..., None]\n",
    "print(x.shape, mask.shape)\n",
    "mask = mask.type(torch.float)\n",
    "x = torch.mul(x, mask)\n",
    "\n",
    "# x[mask] = 0.0\n",
    "print(x)\n",
    "\n",
    "# mask = -10000.0 * mask[:, None, None, :].to(dtype=x.dtype)\n",
    "# print(mask, mask.shape)\n",
    "# mask = mask.expand(batch_size, 1, max_len, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-inf, -inf, -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf, -inf, -inf]]) torch.float32\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]]) torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "def fill_with_neg_inf(t):\n",
    "    \"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"\n",
    "    return t.float().fill_(float(\"-inf\")).type_as(t)\n",
    "\n",
    "tokens_per_sample = 5\n",
    "tmp = fill_with_neg_inf(torch.zeros([tokens_per_sample, tokens_per_sample]))\n",
    "print(tmp, tmp.dtype)\n",
    "\n",
    "output = torch.triu(tmp, 1)\n",
    "\n",
    "print(output, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "def _generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "src = torch.rand((10, 32, 512))\n",
    "print(len(src))\n",
    "\n",
    "mask = _generate_square_subsequent_mask(len(src))\n",
    "print(mask, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000]],\n",
      "\n",
      "        [[0.2500]],\n",
      "\n",
      "        [[0.1250]],\n",
      "\n",
      "        [[0.0625]],\n",
      "\n",
      "        [[0.0312]],\n",
      "\n",
      "        [[0.0156]],\n",
      "\n",
      "        [[0.0078]],\n",
      "\n",
      "        [[0.0039]]]) torch.float32 torch.Size([8, 1, 1])\n",
      "tensor([[[0.0000, 0.5000, 1.0000, 1.5000, 2.0000]],\n",
      "\n",
      "        [[0.0000, 0.2500, 0.5000, 0.7500, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.1250, 0.2500, 0.3750, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.0625, 0.1250, 0.1875, 0.2500]],\n",
      "\n",
      "        [[0.0000, 0.0312, 0.0625, 0.0938, 0.1250]],\n",
      "\n",
      "        [[0.0000, 0.0156, 0.0312, 0.0469, 0.0625]],\n",
      "\n",
      "        [[0.0000, 0.0078, 0.0156, 0.0234, 0.0312]],\n",
      "\n",
      "        [[0.0000, 0.0039, 0.0078, 0.0117, 0.0156]]]) torch.Size([8, 1, 5])\n",
      "tensor([[[0.0000, 0.5000, 1.0000, 1.5000, 2.0000]],\n",
      "\n",
      "        [[0.0000, 0.2500, 0.5000, 0.7500, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.1250, 0.2500, 0.3750, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.0625, 0.1250, 0.1875, 0.2500]],\n",
      "\n",
      "        [[0.0000, 0.0312, 0.0625, 0.0938, 0.1250]],\n",
      "\n",
      "        [[0.0000, 0.0156, 0.0312, 0.0469, 0.0625]],\n",
      "\n",
      "        [[0.0000, 0.0078, 0.0156, 0.0234, 0.0312]],\n",
      "\n",
      "        [[0.0000, 0.0039, 0.0078, 0.0117, 0.0156]]]) torch.Size([8, 1, 5])\n",
      "2\n",
      "fff torch.Size([16, 1, 5])\n",
      "torch.Size([16, 5, 5])\n",
      "tensor([[0.0000,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.0000, 0.1250,   -inf,   -inf,   -inf],\n",
      "        [0.0000, 0.1250, 0.2500,   -inf,   -inf],\n",
      "        [0.0000, 0.1250, 0.2500, 0.3750,   -inf],\n",
      "        [0.0000, 0.1250, 0.2500, 0.3750, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_slopes(n):\n",
    "    def get_slopes_power_of_2(n):\n",
    "        start = (2**(-2**-(math.log2(n)-3)))\n",
    "        ratio = start\n",
    "        return [start*ratio**i for i in range(n)]\n",
    "\n",
    "    if math.log2(n).is_integer():\n",
    "        return get_slopes_power_of_2(n)                   #In the paper, we only train models that have 2^a heads for some a. This function has\n",
    "    else:                                                 #some good properties that only occur when the input is a power of 2. To maintain that even\n",
    "        closest_power_of_2 = 2**math.floor(math.log2(n))  #when the number of heads is not a power of 2, we use this workaround. \n",
    "        return get_slopes_power_of_2(closest_power_of_2) + get_slopes(2*closest_power_of_2)[0::2][:n-closest_power_of_2]\n",
    "\n",
    "attn_heads = 8\n",
    "\n",
    "slopes = torch.Tensor(get_slopes(attn_heads)).unsqueeze(1).unsqueeze(1)\n",
    "print(slopes, slopes.dtype, slopes.shape)\n",
    "\n",
    "maxpos = 5\n",
    "\n",
    "alibi = slopes * torch.arange(maxpos, dtype=torch.float32).unsqueeze(0).unsqueeze(0).expand(attn_heads, -1, -1)\n",
    "print(alibi, alibi.shape)\n",
    "\n",
    "alibi = alibi.view(attn_heads, 1, maxpos)\n",
    "print(alibi, alibi.shape)\n",
    "\n",
    "dd = 11//maxpos\n",
    "print(dd)\n",
    "alibi = alibi.repeat(11//maxpos, 1, 1)\n",
    "print(\"fff\", alibi.shape)\n",
    "\n",
    "mask = output.unsqueeze(0) + alibi\n",
    "print(mask.shape)\n",
    "\n",
    "print(mask[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 8])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "(5, 1)\n",
      "(5, 3)\n",
      "dsfsdf torch.Size([5, 3, 1])\n",
      "torch.Size([5, 3, 8])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "def one_hot(x):\n",
    "    x = x.unsqueeze(-1)\n",
    "    print(x.shape)\n",
    "    condition = torch.zeros(x.shape[0], 8).scatter_(1, x.type(torch.LongTensor), 1)\n",
    "    return condition\n",
    "\n",
    "subject_idx = np.array([0, 1, 3])\n",
    "x = torch.from_numpy(subject_idx).type(torch.FloatTensor)\n",
    "print(x.shape)\n",
    "\n",
    "subject_condition = one_hot(x)\n",
    "print(subject_condition.shape)\n",
    "print(subject_condition)\n",
    "\n",
    "subject_idx = [0, 1, 3, 4, 1]\n",
    "\n",
    "batch_size = len(subject_idx)\n",
    "\n",
    "seq_len = 3\n",
    "\n",
    "def one_hot2(x):\n",
    "    x = x.unsqueeze(-1)\n",
    "    print(\"dsfsdf\", x.shape)\n",
    "    condition = torch.zeros(x.shape[0], 3, 8).scatter_(2, x.type(torch.LongTensor), 1)\n",
    "    return condition\n",
    "\n",
    "# Bx3x8\n",
    "subject_idx = np.expand_dims(subject_idx, axis=1)\n",
    "print(subject_idx.shape)\n",
    "subject_idx = subject_idx.repeat(3, axis=1)\n",
    "print(subject_idx.shape)\n",
    "\n",
    "subject_idx = torch.from_numpy(subject_idx).type(torch.FloatTensor)\n",
    "subject_condition = one_hot2(subject_idx)\n",
    "print(subject_condition.shape)\n",
    "print(subject_condition[3], subject_condition.dtype)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zhanghm/Research/Programming/programming-learning-examples/Python_learning/DL/torch_learn/1-tensor_basics.ipynb Cell 29\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/zhanghm/Research/Programming/programming-learning-examples/Python_learning/DL/torch_learn/1-tensor_basics.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/zhanghm/Research/Programming/programming-learning-examples/Python_learning/DL/torch_learn/1-tensor_basics.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/zhanghm/Research/Programming/programming-learning-examples/Python_learning/DL/torch_learn/1-tensor_basics.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(np\u001b[39m.\u001b[39;49marray([\u001b[39m\"\u001b[39;49m\u001b[39mdata1\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdata2\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/zhanghm/Research/Programming/programming-learning-examples/Python_learning/DL/torch_learn/1-tensor_basics.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(x, x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "x = torch.from_numpy(np.array([\"data1\", \"data2\"]))\n",
    "print(x, x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check is tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| torch.is_tensor(x): True\n",
      "ic| 'Is tensor'\n"
     ]
    }
   ],
   "source": [
    "## Method 1\n",
    "x = torch.rand(4)\n",
    "print(torch.is_tensor(x))\n",
    "\n",
    "## Method 2\n",
    "if isinstance(x, torch.Tensor):\n",
    "    print(\"Is tensor\")\n",
    "else:\n",
    "    print(\"Not a tensor\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check tensor dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5]) 4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(2, 3, 4, 5)\n",
    "print(data.shape, data.dim())\n",
    "print(data.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5]) 4 torch.Size([2, 3, 4, 5])\n",
      "True\n",
      "torch.Size([]) 0 torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(2, 3, 4, 5)\n",
    "print(data.shape, data.dim(), data.shape)\n",
    "print(data.is_contiguous())\n",
    "\n",
    "data = torch.tensor(1.0)\n",
    "print(data.shape, data.dim(), data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tensor types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cuda:0\n",
      "torch.int64 cpu\n",
      "torch.float32 cuda:0\n",
      "torch.float64 torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "## Specify the dtype when creating it\n",
    "src_tensor = torch.tensor([1, 2, 3], dtype=torch.float32, device=device)\n",
    "print(src_tensor.dtype, src_tensor.device)\n",
    "\n",
    "tgt_tensor = torch.tensor([1, 2, 3])\n",
    "print(tgt_tensor.dtype, tgt_tensor.device)\n",
    "\n",
    "## Use to another Tensor to convert the data type and device\n",
    "tgt_tensor = tgt_tensor.to(src_tensor)\n",
    "print(tgt_tensor.dtype, tgt_tensor.device)\n",
    "\n",
    "## Use the type() function\n",
    "src_tensor = torch.rand((3, 2), dtype=torch.float64)\n",
    "tgt_tensor = src_tensor.type(torch.float32)\n",
    "print(src_tensor.dtype, tgt_tensor.dtype)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some member functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> 4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "tensor_data = torch.randn((3, 4, 5))\n",
    "tensor_size = tensor_data.shape[1] # or using tensor_data.size(1)\n",
    "print(type(tensor_size), tensor_size)\n",
    "print(tensor_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand\n",
    "https://discuss.pytorch.org/t/expand-vs-repeat-semantic-difference/59789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.]]]) torch.Size([1, 1, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[10.,  0.,  0.]]])\n",
      "tensor([[[10.,  0.,  0.],\n",
      "         [10.,  0.,  0.]],\n",
      "\n",
      "        [[10.,  0.,  0.],\n",
      "         [10.,  0.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.zeros(1, 1, 3)\n",
    "print(x, x.shape)\n",
    "\n",
    "y = x.expand(2, 2, -1)\n",
    "print(y, y.shape)\n",
    "\n",
    "y[0,0,0] = 10  # expand would not deepcopy the memory\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape and Transpose\n",
    "https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape vs. view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5]) torch.Size([6])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) torch.Size([2, 3])\n",
      "tensor([[100,   1,   2],\n",
      "        [  3,   4,   5]]) tensor([100,   1,   2,   3,   4,   5])\n",
      "tensor([[100,   1],\n",
      "        [  2,   3],\n",
      "        [  4,   5]]) torch.Size([3, 2])\n",
      "True\n",
      "tensor([[100,   2,   4],\n",
      "        [  1,   3,   5]]) False\n",
      "tensor([[100,   2],\n",
      "        [  4,   1],\n",
      "        [  3,   5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_function():\n",
    "    input_data = torch.arange(6)\n",
    "    print(input_data, input_data.shape)\n",
    "    input_data_view = input_data.view(2, 3)\n",
    "    print(input_data_view, input_data_view.shape)\n",
    "    input_data_view[0, 0] = 100 # NOTE: This will change the input_data as well\n",
    "    print(input_data_view, input_data)\n",
    "\n",
    "    # print(input_data.reshape(3, 2))\n",
    "    input_data_view2 = input_data.view(3, 2)\n",
    "    print(input_data_view2, input_data_view2.shape)\n",
    "\n",
    "    print(input_data_view.is_contiguous())\n",
    "    input_data_transpose = input_data_view2.transpose(0, 1) # NOTE: transpose will change the contiguous\n",
    "    print(input_data_transpose, input_data_transpose.is_contiguous())\n",
    "\n",
    "    # error_data = input_data_transpose.view(3, 2) # NOTE: view function can only apply on contiguous data\n",
    "    ok_data = input_data_transpose.reshape(3, 2) \n",
    "    print(ok_data)\n",
    "\n",
    "test_function()\n",
    "\n",
    "# input_data = input_data.transpose(0, 1)\n",
    "\n",
    "# ## view function\n",
    "# flatten_input_data = input_data.view(-1)\n",
    "# print(flatten_input_data, flatten_input_data.shape)\n",
    "# flatten_input_data[3] = 100 \n",
    "# print(input_data)\n",
    "\n",
    "## reshape function\n",
    "# flatten_input_data = input_data.reshape(-1)\n",
    "# print(flatten_input_data, flatten_input_data.shape)\n",
    "# flatten_input_data[3] = 100 # NOTE: This will change the input_data as well\n",
    "# print(input_data)\n",
    "\n",
    "# flatten_input_data = input_data.reshape(-1, 1, 1)\n",
    "# print(flatten_input_data.shape)\n",
    "# print(flatten_input_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| input_data.shape: torch.Size([3, 12, 12])\n",
      "ic| input_data.shape: torch.Size([1, 3, 12, 12])\n",
      "ic| samples.shape: torch.Size([5, 2048, 3])\n",
      "    centers.shape: torch.Size([5, 512, 3])\n",
      "ic| samples.shape: torch.Size([5, 2048, 1, 3])\n",
      "    centers.shape: torch.Size([5, 1, 512, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2048, 1, 3]), torch.Size([5, 1, 512, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randn((3, 12, 12))\n",
    "print(input_data.shape)\n",
    "\n",
    "input_data = input_data[None]\n",
    "print(input_data.shape)\n",
    "\n",
    "\n",
    "samples = torch.randn(5, 2048, 3)\n",
    "centers = torch.randn(5, 512, 3)\n",
    "\n",
    "print(samples.shape, centers.shape)\n",
    "\n",
    "samples = samples[:, :, None]\n",
    "centers = centers[:, None]\n",
    "print(samples.shape, centers.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different data type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([1., 2., 3.])\n",
      "torch.int64\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "pred = torch.FloatTensor(np.array([1,2,3]))\n",
    "print(pred.dtype)\n",
    "print(pred)\n",
    "pred = pred.to(torch.int64)\n",
    "print(pred.dtype)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "Labels is not None\n"
     ]
    }
   ],
   "source": [
    "labels = None\n",
    "labels = torch.tensor([1, 2, 3])\n",
    "print(labels.dtype)\n",
    "if labels is None: # use 'is' instead of ==\n",
    "    print(\"Labels is None\")\n",
    "else:\n",
    "    print(\"Labels is not None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.2346e+00,  3.7939e-01, -1.9367e+00,  1.3094e+00,  4.6663e-01],\n",
      "          [ 3.4819e-01, -5.6895e-01, -1.5108e+00,  7.0780e-01,  9.0777e-01],\n",
      "          [ 4.6561e-01,  2.1563e+00, -2.3255e+00, -6.6472e-01,  5.5147e-01],\n",
      "          [ 9.4951e-01, -3.3740e-01, -6.2161e-02,  4.8511e-01, -1.4107e-01],\n",
      "          [ 6.3537e-01,  1.5464e+00,  2.0419e+00,  2.4523e-01,  2.2240e+00]],\n",
      "\n",
      "         [[-5.4798e-01,  1.6411e-01, -2.4302e-01, -2.1069e+00, -1.1748e+00],\n",
      "          [ 5.8614e-01, -1.0792e+00,  8.6184e-02,  2.6984e-02,  3.7680e-01],\n",
      "          [-4.2325e-02,  5.9603e-01, -5.9892e-01,  6.5933e-01,  9.7178e-01],\n",
      "          [-1.4920e+00, -2.1150e-01, -2.5007e-01, -2.6350e-01, -7.3031e-01],\n",
      "          [-8.8017e-01, -1.0805e+00, -8.5367e-01,  2.3745e+00,  1.7426e+00]],\n",
      "\n",
      "         [[ 3.5111e-01, -1.0492e+00, -6.6652e-01,  1.4015e+00,  2.0608e+00],\n",
      "          [-1.2575e+00, -4.0794e-01,  2.2955e-02, -1.0286e+00,  6.4215e-01],\n",
      "          [-8.6350e-01, -2.7992e-01, -2.8991e-01,  9.1334e-01,  3.0354e-01],\n",
      "          [ 2.1641e-01, -1.9566e-01,  1.0338e+00,  1.1264e+00,  4.0221e-01],\n",
      "          [ 2.0189e+00, -1.6187e+00,  4.1265e-01, -6.0841e-01,  1.8968e-01]],\n",
      "\n",
      "         [[-1.8429e-01,  8.0868e-01,  1.7447e+00, -1.0210e+00,  1.5757e+00],\n",
      "          [-3.1405e-02, -2.0191e+00,  1.1914e+00,  1.1556e+00,  1.6644e+00],\n",
      "          [-1.1875e-01,  9.0442e-01, -1.1304e+00,  6.0358e-01,  1.0516e+00],\n",
      "          [-4.0070e-01, -1.1804e+00,  1.9238e+00, -1.9617e+00,  1.0318e-01],\n",
      "          [ 6.5388e-01,  2.0243e+00, -1.6899e+00, -5.0559e-02,  1.6300e+00]],\n",
      "\n",
      "         [[-9.7397e-01,  1.1398e+00,  1.4172e+00, -2.7411e+00, -8.6943e-01],\n",
      "          [-5.4372e-01,  1.2351e+00,  2.0426e-01,  9.3565e-01,  1.8707e-01],\n",
      "          [-2.0517e+00,  2.0031e+00,  1.2341e+00, -1.8753e-01, -1.8052e-01],\n",
      "          [-1.2378e+00,  1.6180e-01, -7.2887e-01, -1.2642e-01,  1.0855e+00],\n",
      "          [ 2.7149e-01,  1.0281e-01, -6.0565e-01, -8.3267e-02,  1.1175e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5715e-01,  2.4055e+00,  8.4600e-01,  5.2831e-01, -1.1693e+00],\n",
      "          [-5.2568e-01, -1.0548e+00, -6.7944e-01, -8.2646e-01,  2.7494e-01],\n",
      "          [ 6.2002e-01,  1.5460e+00,  1.2003e+00, -3.9887e-01,  1.1501e+00],\n",
      "          [ 6.7257e-02,  1.6964e-01, -6.8771e-01, -1.2509e+00, -5.2786e-03],\n",
      "          [-1.3184e-01,  4.0219e-01, -1.3801e+00, -8.3485e-01,  1.4085e+00]],\n",
      "\n",
      "         [[-9.2888e-01,  3.5968e-01, -1.1723e+00,  2.4273e-01,  1.7805e+00],\n",
      "          [-3.7535e-01, -1.8026e+00,  3.5588e-01,  1.0069e+00, -6.2580e-01],\n",
      "          [-6.8609e-01,  2.6151e-01, -8.5780e-01, -1.0749e-01, -1.1678e-01],\n",
      "          [ 1.0862e-01,  1.2231e+00, -8.5023e-01, -7.5645e-01, -7.0967e-01],\n",
      "          [-2.5306e+00,  9.8693e-02, -1.7506e+00,  1.7387e-01, -3.2363e-01]],\n",
      "\n",
      "         [[-4.2739e-01, -4.9143e-01, -5.2440e-01, -4.3537e-01, -2.7199e+00],\n",
      "          [-8.4410e-01, -4.5774e-01, -5.1657e-01,  7.0558e-01, -1.0244e+00],\n",
      "          [-7.0609e-01,  1.4285e-01,  2.8346e-01, -9.8969e-01,  2.8631e-01],\n",
      "          [ 1.2106e+00, -2.3849e-01,  7.4692e-01,  2.0750e+00,  2.0930e-01],\n",
      "          [ 1.0754e+00,  1.2247e+00,  1.8562e+00, -2.7204e-01, -2.7231e-01]],\n",
      "\n",
      "         [[-4.5841e-02, -2.4852e-01,  8.9912e-02,  3.4969e-01, -2.7855e-01],\n",
      "          [ 4.1676e-02, -1.6586e-01,  4.9496e-01,  1.3699e+00,  6.7802e-01],\n",
      "          [ 5.2222e-01,  1.0178e-01,  1.1983e+00, -4.0592e-01, -9.0113e-01],\n",
      "          [ 1.6810e+00,  1.9428e+00, -9.6141e-01,  1.2544e+00, -8.7635e-01],\n",
      "          [ 2.6562e-01,  1.6067e+00,  1.0692e+00, -4.1490e-01,  8.7475e-01]],\n",
      "\n",
      "         [[-1.3481e+00, -8.2538e-01, -7.3892e-01,  1.0084e+00, -4.9712e-01],\n",
      "          [ 5.7413e-01,  3.6640e-01, -9.4849e-01,  6.9340e-01,  8.8671e-01],\n",
      "          [-1.9473e+00,  1.3217e+00,  4.8450e-01, -1.1724e+00,  2.0151e+00],\n",
      "          [-6.8382e-02, -2.7857e-02, -9.5730e-01, -1.6270e+00, -2.6060e-01],\n",
      "          [-7.3793e-01,  5.3350e-01, -2.9324e-01,  1.0894e+00, -5.4742e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7109e+00,  1.3023e+00, -1.3803e+00, -7.1883e-01,  9.2907e-01],\n",
      "          [ 1.7866e+00, -2.3257e-01,  4.9878e-01, -8.1394e-01, -1.1929e-01],\n",
      "          [ 2.8733e-01, -7.3548e-01, -5.0384e-02, -1.4352e+00, -1.1997e-03],\n",
      "          [ 7.3440e-02,  6.3864e-01,  1.0079e+00,  5.4344e-01,  1.3513e-01],\n",
      "          [-1.4297e+00, -6.2510e-01, -1.5934e+00,  1.1927e+00,  1.6565e+00]],\n",
      "\n",
      "         [[ 1.2001e+00,  9.7253e-02, -1.2458e+00, -5.8182e-01,  1.3888e+00],\n",
      "          [ 1.2897e-01,  5.3670e-01,  5.7344e-01, -9.8593e-02, -9.8506e-01],\n",
      "          [ 7.1238e-01,  7.6798e-01, -9.4886e-01, -1.0887e+00,  7.2283e-01],\n",
      "          [ 8.4153e-01,  1.8844e-02, -1.1192e+00, -3.3701e-01,  3.3998e-01],\n",
      "          [ 3.1752e-01, -1.2712e+00,  1.3944e+00, -9.1838e-01, -1.1232e+00]],\n",
      "\n",
      "         [[-1.1130e+00,  5.8787e-01,  9.0246e-01,  2.3069e+00,  2.4239e-02],\n",
      "          [-2.0671e+00,  5.6272e-01,  9.2889e-01,  1.0599e+00,  6.2464e-01],\n",
      "          [-2.0304e-01, -2.0553e-01, -9.5962e-01,  1.1244e-01, -1.5785e+00],\n",
      "          [-9.3650e-01,  7.8743e-01, -7.1150e-01, -3.3500e-01, -4.7108e-02],\n",
      "          [ 8.3871e-01,  6.4528e-01,  1.0008e+00,  6.7690e-02,  8.1117e-01]],\n",
      "\n",
      "         [[ 6.9302e-01, -1.9515e+00,  2.7061e-01, -6.8106e-01, -2.4271e-01],\n",
      "          [ 1.5973e+00, -2.5634e-01, -2.0160e+00, -1.2460e+00,  7.9957e-01],\n",
      "          [ 9.6181e-01, -9.1129e-01, -1.0838e+00,  1.7153e+00,  1.0231e+00],\n",
      "          [-1.0809e+00, -1.2233e+00, -9.3662e-01,  1.2365e-01, -7.3753e-01],\n",
      "          [-3.2826e-01, -1.0198e+00,  7.8025e-01,  3.0057e-01,  6.3524e-02]],\n",
      "\n",
      "         [[ 7.3830e-01, -3.1824e-01,  7.4991e-01,  1.7783e+00,  1.3528e+00],\n",
      "          [-1.4204e-01, -1.1918e+00,  1.1593e+00,  7.9833e-03,  6.1654e-01],\n",
      "          [-4.8035e-01,  3.1101e-01,  7.3892e-02,  6.1681e-01,  1.8110e-01],\n",
      "          [-7.3294e-01,  2.6680e-01, -1.0728e+00,  2.0565e+00,  5.6888e-01],\n",
      "          [-4.4930e-01,  4.1409e-01, -1.0088e+00,  2.5203e-02, -1.3462e-01]]]])\n",
      "torch.Size([5, 5, 5])\n",
      "torch.Size([5, 5, 5])\n",
      "torch.Size([5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "## Loop the Tensor\n",
    "data_a = torch.randn(3, 5, 5, 5)\n",
    "print(data_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 400, 3])\n",
      "torch.Size([400, 3])\n"
     ]
    }
   ],
   "source": [
    "### Create meshgrid\n",
    "# Ray helpers\n",
    "def get_rays(H, W, K, c2w):\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))  # pytorch's meshgrid has indexing='ij'\n",
    "    i = i.t()\n",
    "    j = j.t()\n",
    "    dirs = torch.stack([(i-K[0][2])/K[0][0], -(j-K[1][2])/K[1][1], -torch.ones_like(i)], -1)\n",
    "\n",
    "    # Rotate ray directions from camera frame to the world frame\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    # Translate camera frame's origin to the world frame. It is the origin of all rays.\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "    return rays_o, rays_d\n",
    "\n",
    "H, W, focal = 400, 400, 555.55\n",
    "K = np.array([\n",
    "            [focal, 0, 0.5*W],\n",
    "            [0, focal, 0.5*H],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "c2w = np.random.rand(3, 4)\n",
    "get_rays(H, W, K, c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) tensor([12,  2,  3])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "data_a = torch.tensor([1, 2, 3])\n",
    "\n",
    "data_b = data_a.clone()\n",
    "\n",
    "data_b[0] = 12\n",
    "print(data_a, data_b)\n",
    "\n",
    "print(data_a.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[[ 0,  1],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7],\n",
      "         [10, 11]]]) torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.arange(12).reshape(6, 2)\n",
    "print(data)\n",
    "index = torch.tensor([0, 2, 3, 5])\n",
    "index = index.unsqueeze(0)\n",
    "print(index.shape)\n",
    "\n",
    "output = data[index]\n",
    "print(output, output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice operations for Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 48, 48])\n",
      "torch.Size([2, 11, 48, 48])\n",
      "18\n",
      "12\n",
      "[1, 4, 7, 10, 13, 16]\n"
     ]
    }
   ],
   "source": [
    "data_a = torch.rand((2, 21, 48, 48))\n",
    "length = 10\n",
    "data_a_fw = data_a[:, :length-1, ...]\n",
    "print(data_a_fw.shape)\n",
    "\n",
    "data_a_bw = data_a[:, length:, ...].flip(1)\n",
    "print(data_a_bw.shape)\n",
    "\n",
    "t = 19\n",
    "t = t // 3 * 3\n",
    "print(t)\n",
    "\n",
    "n = 2\n",
    "n_clip = n * t // 3\n",
    "print(n_clip)\n",
    "\n",
    "hr_flow = list(range(19))\n",
    "hr_flow_bw = hr_flow[0:t:3]\n",
    "print(hr_flow_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masked_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4402, -2.4868, -0.9217],\n",
      "        [-0.5635,  1.9211, -0.9840]])\n",
      "tensor([[0.4402, 0.0000, 0.0000],\n",
      "        [0.0000, 1.9211, 0.0000]])\n",
      "tensor([[0.4402, 0.0000, 0.0000],\n",
      "        [0.0000, 1.9211, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.randn(2, 3)\n",
    "print(input)\n",
    "\n",
    "output = input.masked_fill(input < 0, 0)\n",
    "print(output)\n",
    "\n",
    "input.masked_fill_(input < 0, 0)\n",
    "print(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor([[[-1.1381, -0.0397],\n",
      "         [ 1.6323,  0.1880]],\n",
      "\n",
      "        [[-0.8910,  0.2037],\n",
      "         [ 0.2593,  0.2279]],\n",
      "\n",
      "        [[-0.2807,  1.2331],\n",
      "         [-0.5396, -0.1515]],\n",
      "\n",
      "        [[ 1.4733, -0.2060],\n",
      "         [ 0.9064,  0.4809]],\n",
      "\n",
      "        [[ 0.0519, -1.3739],\n",
      "         [-0.3992, -2.0197]]]) torch.Size([5, 2, 2])\n",
      "tensor([[[-1.1381, -0.0397],\n",
      "         [ 1.6323,  0.1880]],\n",
      "\n",
      "        [[-0.2807,  1.2331],\n",
      "         [-0.5396, -0.1515]],\n",
      "\n",
      "        [[ 0.0519, -1.3739],\n",
      "         [-0.3992, -2.0197]]])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "## Get the submatrix according to the boolean mask\n",
    "\n",
    "mask = torch.tensor([True, False, True, False, True])\n",
    "print(mask.shape)\n",
    "data = torch.randn((5, 2, 2))\n",
    "print(data, data.shape)\n",
    "\n",
    "mask_data = data[mask]\n",
    "print(mask_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## narrow & unbind functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[ 1.9275,  0.8109,  0.9534],\n",
      "        [ 1.9258,  0.5665, -0.8327],\n",
      "        [ 0.4763, -1.5188, -0.9933]])\n",
      "tensor([[ 1.9258,  0.5665, -0.8327],\n",
      "        [ 0.4763, -1.5188, -0.9933]]) torch.Size([2, 3])\n",
      "tensor([[ 0.8109,  0.9534],\n",
      "        [ 0.5665, -0.8327],\n",
      "        [-1.5188, -0.9933]])\n",
      "unbind function\n",
      "(tensor([1.9275, 0.8109, 0.9534]), tensor([ 1.9258,  0.5665, -0.8327]), tensor([ 0.4763, -1.5188, -0.9933])) <class 'tuple'>\n",
      "(tensor([1.9275, 1.9258, 0.4763]), tensor([ 0.8109,  0.5665, -1.5188]), tensor([ 0.9534, -0.8327, -0.9933]))\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(3, 3)\n",
    "print(\"x:\")\n",
    "print(x)\n",
    "\n",
    "print(\"narrow function\") # https://pytorch.org/docs/master/generated/torch.narrow.html\n",
    "row_slice = x.narrow(0, 1, 2) # (dim, start_idx, length)\n",
    "print(row_slice, row_slice.shape) # column dimension keep unchanged\n",
    "\n",
    "print(x.narrow(1, 1, 2))\n",
    "\n",
    "print(\"unbind function\") # https://pytorch.org/docs/master/generated/torch.unbind.html\n",
    "row_unbind = x.unbind(0)\n",
    "print(row_unbind, type(row_unbind))\n",
    "\n",
    "col_unbind = x.unbind(1)\n",
    "print(col_unbind)\n",
    "\n",
    "x_iter = iter(col_unbind)\n",
    "dd = next(x_iter)\n",
    "print(dd.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a matrix all negtive values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8786,  0.6568,  0.7157, -0.8748],\n",
      "         [ 0.1681, -2.3124, -1.1988,  2.5490],\n",
      "         [-1.0920, -1.5986, -0.1188,  0.2182]],\n",
      "\n",
      "        [[-0.9203,  0.2892,  1.1653, -1.7656],\n",
      "         [ 1.0775,  2.1220, -0.3829,  1.9707],\n",
      "         [ 1.3156, -0.6420, -0.3613,  0.0979]]])\n",
      "tensor([[[0.0000, 0.6568, 0.7157, 0.0000],\n",
      "         [0.1681, 0.0000, 0.0000, 2.5490],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2182]],\n",
      "\n",
      "        [[0.0000, 0.2892, 1.1653, 0.0000],\n",
      "         [1.0775, 2.1220, 0.0000, 1.9707],\n",
      "         [1.3156, 0.0000, 0.0000, 0.0979]]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn((2, 3, 4))\n",
    "print(input_tensor)\n",
    "input_tensor = torch.max(torch.zeros_like(input_tensor), input_tensor)\n",
    "print(input_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]]) torch.Size([2, 3])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3]]) torch.Size([2, 9])\n",
      "torch.Size([3])\n",
      "torch.Size([5, 1, 3])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[1, 2, 3]],\n",
      "\n",
      "        [[1, 2, 3]],\n",
      "\n",
      "        [[1, 2, 3]],\n",
      "\n",
      "        [[1, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "### squeeze和unsqueeze的用法 https://pytorch.org/docs/stable/generated/torch.unsqueeze.html\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(torch.unsqueeze(x, 0))\n",
    "print(torch.unsqueeze(x, 1))\n",
    "\n",
    "### Expand函数不复制张量元素\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x = x.expand(2, 3)\n",
    "print(x, x.shape)\n",
    "\n",
    "### Repeat函数复制张量元素\n",
    "y = torch.tensor([1, 2, 3])\n",
    "y = y.repeat(2, 3)\n",
    "print(y, y.shape)\n",
    "\n",
    "### 使用Repeat可以为张量增加维度\n",
    "y = torch.tensor([1, 2, 3])\n",
    "print(y.shape)\n",
    "y = y.unsqueeze(0).repeat(5, 1, 1)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conca, Stack operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]]) torch.Size([3, 2, 3])\n",
      "tensor([[[0, 0, 0],\n",
      "         [1, 1, 1],\n",
      "         [2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3],\n",
      "         [4, 4, 4],\n",
      "         [5, 5, 5]]]) torch.Size([2, 3, 3])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## stack operation\n",
    "import torch\n",
    "\n",
    "data = torch.arange(6).reshape(2, 3)\n",
    "print(data)\n",
    "\n",
    "data_a = [data, data, data]\n",
    "data_b = torch.stack(data_a, dim=0)\n",
    "print(data_b, data_b.shape)\n",
    "\n",
    "data_a = [data, \n",
    "          data, \n",
    "          data]\n",
    "data_b = torch.stack(data_a, dim=-1)\n",
    "print(data_b, data_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5, 96, 96])\n",
      "torch.Size([5, 2])\n",
      "Stack result: \n",
      " tensor([[[0.9829, 0.8784, 0.4056],\n",
      "         [0.7488, 0.4011, 0.5612]],\n",
      "\n",
      "        [[0.1599, 0.0827, 0.1275],\n",
      "         [0.3106, 0.1268, 0.2426]],\n",
      "\n",
      "        [[0.5175, 0.6330, 0.8574],\n",
      "         [0.6942, 0.8501, 0.3712]]]) torch.Size([3, 2, 3])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "### 连接堆叠操作\n",
    "data_a = torch.randn(2, 3, 5, 96, 96)\n",
    "data_b = torch.randn(2, 3, 5, 96, 96)\n",
    "data_ab = torch.cat([data_a[:,i] for i in range(data_a.size(1))], dim=0)\n",
    "print(data_ab.shape)\n",
    "\n",
    "data_a = [torch.rand(5), torch.rand(5)]\n",
    "data_b = torch.stack(data_a, 1)\n",
    "print(data_b.shape)\n",
    "\n",
    "data_a = [torch.rand((2,3)), torch.rand((2,3)), torch.rand((2,3))]\n",
    "data_b = torch.stack(data_a, dim=0)\n",
    "print(\"Stack result: \\n\", data_b, data_b.shape)\n",
    "\n",
    "input_list = torch.Tensor([1, 2, 3, 4])\n",
    "\n",
    "print(input_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的shape： torch.Size([2, 2, 3])\n",
      "b: (tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]), tensor([[[ 7,  8,  9],\n",
      "         [10, 11, 12]]])) 2\n",
      "c: (tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[7, 8, 9]]]), tensor([[[ 4,  5,  6]],\n",
      "\n",
      "        [[10, 11, 12]]]))\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[[1,2,3],[4,5,6]],\n",
    "                [[7,8,9],[10,11,12]]])\n",
    "print(\"a的shape：\",a.shape)\n",
    "#在第0维上进行split\n",
    "b=torch.split(a, 1)\n",
    "print(\"b:\", b, len(b))\n",
    "#在第1维上进行split\n",
    "c=torch.split(a,[1,1],1)\n",
    "print(\"c:\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "30 30\n",
      "torch.Size([2, 10, 3, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "gt_with_border = torch.rand((2, 10,3,128, 128))\n",
    "border_size = int(1.5*3.0)\n",
    "print(border_size)\n",
    "\n",
    "scale = 4\n",
    "n, t, c, gt_h, gt_w = gt_with_border.size()\n",
    "lr_h = (gt_h - 2*border_size)//scale\n",
    "lr_w = (gt_w - 2*border_size)//scale\n",
    "print(lr_h, lr_w)\n",
    "\n",
    "gt_data = gt_with_border[\n",
    "                ...,\n",
    "                border_size: border_size + scale*lr_h,\n",
    "                border_size: border_size + scale*lr_w\n",
    "            ]\n",
    "print(gt_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile and repeat the Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]]]) torch.Size([1, 2, 2])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [3, 4]]]) torch.Size([3, 2, 2])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4]]) torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "## From pytorch 1.8, the torch.tile function has been removed,\n",
    "## we can still use the repeat function\n",
    "import torch\n",
    "y = torch.tensor([[1, 2], [3, 4]])[None]\n",
    "print(y, y.shape)\n",
    "\n",
    "y = y.repeat((3, 1, 1))\n",
    "print(y, y.shape)\n",
    "\n",
    "y = y.reshape(-1, 2)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 0., 0.],\n",
      "        [4., 5., 6., 7., 8.],\n",
      "        [8., 9., 0., 0., 0.]])\n",
      "torch.Size([3, 3, 3, 2])\n",
      "tensor([[[0.6115, 0.5482],\n",
      "         [0.9795, 0.7042],\n",
      "         [0.9924, 0.8721]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "\n",
    "input_x =[[1,2,3],[4,5,6,7,8],[8,9]]\n",
    "norm_data_pad = pad_sequence([torch.from_numpy(np.array(x)) for x in input_x], batch_first=True).float()\n",
    "print(norm_data_pad)\n",
    "\n",
    "arr1 = torch.rand(1, 3, 2)\n",
    "arr2 = torch.rand(2, 3, 2)\n",
    "arr3 = torch.rand(3, 3, 2)\n",
    "\n",
    "norm_data_pad = pad_sequence([arr1, arr2, arr3], batch_first=True).float()\n",
    "print(norm_data_pad.shape)\n",
    "print(norm_data_pad[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 42, 64])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 255])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1, 42, 64)\n",
    "print(x.shape)\n",
    "\n",
    "cpatch = x[:, 0:16, 0:16]\n",
    "cpatch = cpatch.reshape(cpatch.shape[0], -1)\n",
    "print(cpatch.shape)\n",
    "\n",
    "cpatch = cpatch[:, :-1]\n",
    "print(cpatch.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0583,  0.7821,  0.8115],\n",
      "        [ 1.6770,  0.3767, -0.4914]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 0.0583,  0.7821,  0.8115,  0.0583,  0.7821,  0.8115],\n",
      "        [ 1.6770,  0.3767, -0.4914,  1.6770,  0.3767, -0.4914]])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.randn(2, 3)\n",
    "print(input)\n",
    "print(input.shape)\n",
    "\n",
    "input = input.repeat(1, 2)\n",
    "print(input)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2284, -1.9785,  0.4349, -0.3315],\n",
      "        [ 1.0020,  0.4194, -0.3357, -0.3839],\n",
      "        [ 0.7561,  1.2428,  0.0676, -0.4730],\n",
      "        [-0.5543, -0.4096,  1.9598,  0.4670]])\n",
      "tensor([[[[[ 1.2284],\n",
      "           [-1.9785]],\n",
      "\n",
      "          [[ 0.4349],\n",
      "           [-0.3315]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0020],\n",
      "           [ 0.4194]],\n",
      "\n",
      "          [[-0.3357],\n",
      "           [-0.3839]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.7561],\n",
      "           [ 1.2428]],\n",
      "\n",
      "          [[ 0.0676],\n",
      "           [-0.4730]]],\n",
      "\n",
      "\n",
      "         [[[-0.5543],\n",
      "           [-0.4096]],\n",
      "\n",
      "          [[ 1.9598],\n",
      "           [ 0.4670]]]]])\n",
      "torch.Size([2, 2, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "downsample = 2\n",
    "input = torch.randn(4, 4)\n",
    "print(input)\n",
    "H, W = input.shape\n",
    "gt_depths = input.view(H // downsample,\n",
    "                       downsample, W // downsample,\n",
    "                       downsample, 1)\n",
    "print(gt_depths)\n",
    "print(gt_depths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2284, -1.9785,  1.0020,  0.4194],\n",
      "        [ 0.4349, -0.3315, -0.3357, -0.3839],\n",
      "        [ 0.7561,  1.2428, -0.5543, -0.4096],\n",
      "        [ 0.0676, -0.4730,  1.9598,  0.4670]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "gt_depths = gt_depths.permute(0, 2, 4, 1, 3).contiguous()\n",
    "gt_depths = gt_depths.view(-1, downsample * downsample)\n",
    "print(gt_depths)\n",
    "print(gt_depths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2284e+00, 1.0000e+05, 1.0020e+00, 4.1941e-01],\n",
      "        [4.3488e-01, 1.0000e+05, 1.0000e+05, 1.0000e+05],\n",
      "        [7.5608e-01, 1.2428e+00, 1.0000e+05, 1.0000e+05],\n",
      "        [6.7553e-02, 1.0000e+05, 1.9598e+00, 4.6698e-01]])\n",
      "tensor([0.4194, 0.4349, 0.7561, 0.0676])\n",
      "torch.Size([4])\n",
      "tensor([[0.4194, 0.4349],\n",
      "        [0.7561, 0.0676]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "gt_depths_tmp = torch.where(gt_depths < 0.0,\n",
    "                            1e5 * torch.ones_like(gt_depths),\n",
    "                            gt_depths)\n",
    "print(gt_depths_tmp)\n",
    "gt_depths = torch.min(gt_depths_tmp, dim=-1).values\n",
    "print(gt_depths)\n",
    "print(gt_depths.shape)\n",
    "\n",
    "gt_depths = gt_depths.view(H // downsample,\n",
    "                            W // downsample)\n",
    "\n",
    "print(gt_depths)\n",
    "print(gt_depths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "tensor([[[ True, False,  True,  True, False],\n",
      "         [ True, False,  True,  True, False],\n",
      "         [False, False,  True,  True,  True]]]) torch.Size([1, 3, 5])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.randn(1, 3, 5)\n",
    "print(input.shape)\n",
    "mask = torch.randint_like(input, 0, 2).bool()\n",
    "print(mask, mask.shape)\n",
    "\n",
    "output = input[mask]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06632878 -0.11755253 -0.97472341 -0.44844803]\n",
      " [-0.46412638  2.17743045 -1.74345384  1.89693474]\n",
      " [-0.5920778  -0.08032467 -1.27751084  1.40742789]\n",
      " [-0.72611626 -1.27796876  0.00784594  0.45861456]]\n",
      "[[-0.06632878 -0.11755253 -0.97472341 -0.44844803]\n",
      " [-0.46412638  2.17743045 -1.74345384  1.89693474]\n",
      " [-0.5920778  -0.08032467 -1.27751084  1.40742789]\n",
      " [-0.72611626 -1.27796876  0.00784594  0.45861456]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "curr_img2global = np.random.randn(4, 4)\n",
    "adj_img_to_global = np.random.randn(4, 4)\n",
    "\n",
    "curr_img_to_adj_img = np.linalg.inv(adj_img_to_global) @ curr_img2global\n",
    "print(curr_img_to_adj_img)\n",
    "\n",
    "curr_img2global[:2] *= 0.2\n",
    "adj_img_to_global[:2] *= 0.2\n",
    "\n",
    "curr_img_to_adj_img = np.linalg.inv(adj_img_to_global) @ curr_img2global\n",
    "print(curr_img_to_adj_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.Tensor([])\n",
    "all_inputs = [inputs, inputs]\n",
    "data = torch.stack(all_inputs)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 3, 4])\n",
      "torch.Size([2, 10, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sh = torch.randn(2, 10, 3, 4)\n",
    "print(sh.shape)\n",
    "\n",
    "opacities = torch.randn(2, 10)\n",
    "\n",
    "sh_2 = sh.broadcast_to((*opacities.shape, 3, 4))\n",
    "print(sh_2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
